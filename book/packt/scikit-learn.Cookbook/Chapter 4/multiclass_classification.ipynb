{
 "metadata": {
  "name": "",
  "signature": "sha256:abe9b3cd24492ae2801d37f2fd22a0a92857c8ff50601c6056f63366eda23c8e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Getting ready"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this recipe we'll look at multiclass classification.  Depending on your choice of alogrithm, you either get multiclass classification for free, or you have to define a scheme for comparison.  For example, when we're working with linear models, such as logistic regression, we need to use the OneVsRestClassifier.  This scheme will create a classifier for each class."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#How to do it"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we'll walk through a cursory example of a Decision Tree fitting a multiclass dataset.  Like we talked about, with some classifiers we get multiclass for free, so we'll just fit the example to prove it works and move on.\n",
      "\n",
      "Second, we'll actually incorporate the OneVsRestClassifier into our model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = datasets.make_classification(n_samples=10000, n_classes=3, n_informative=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier\n",
      "dt = DecisionTreeClassifier()\n",
      "dt.fit(X, y)\n",
      "dt.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "array([1, 1, 0, ..., 2, 1, 1])"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, with little effort we were able to fit a classifier.\n",
      "\n",
      "Now to the case of the multiclass classifier.  This will require us to import the OneVsRestClassifier.  We'll also import the LogisticRegression while we're at it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll override the LogisticRegression classifier.  Also, notice that we can parallelize this.  If we think about how One vs Rest works, it's just training seperate models then comparing.  So we can train the data seperately at the same time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlr = OneVsRestClassifier(LogisticRegression(), n_jobs=2)\n",
      "mlr.fit(X, y)\n",
      "mlr.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([1, 1, 0, ..., 2, 1, 1])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#How it works"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we wanted to really quickly create our own OneVsRestClassifier, how might we do that?\n",
      "\n",
      "First we'd want to construct a way to iterate through the classes and train a classifier for each classifier.  Then we'll need to predict each class first the rest."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_one_vs_rest(y, class_label):\n",
      "    y_train = (y == class_label).astype(int)\n",
      "    \n",
      "    return y_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifiers = []\n",
      "for class_i in sorted(np.unique(y)):\n",
      "    \n",
      "    l = LogisticRegression()\n",
      "    y_train = train_one_vs_rest(y, class_i)\n",
      "\n",
      "    l.fit(X, y_train)\n",
      "    \n",
      "    classifiers.append(l)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, so now that we have a one vs rest scheme setup, all we need to do is evaluate that data point's likelihood for each classifier.  We will then assign the classifier to the datapoint with the largest liklihood."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For example, let's predict `X[0]`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for classifier in classifiers:\n",
      "    \n",
      "    print classifier.predict_proba(X[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.90443776  0.09556224]]\n",
        "[[ 0.03701073  0.96298927]]\n",
        "[[ 0.98492829  0.01507171]]\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see the 2nd classifier (the one in index 1) has the highest likelihood of being \"positive\", therefore we'll assign 1 to that point."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}